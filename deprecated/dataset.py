# -*- coding: utf-8 -*-
"""dataset

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Q28NG7OYSaE-gDGlPwtH_HBEGZC27qOi
"""

import librosa
import soundfile as sf
import os
import numpy as np
import random
import stempeg
import json
import csv

def mix_audio(base_audio, overlay_audio, snr_db):
    if base_audio.ndim == 1:
        base_audio = np.stack((base_audio, base_audio), axis=-1)
    if overlay_audio.ndim == 1:
        overlay_audio = np.stack((overlay_audio, overlay_audio), axis=-1)

    base_rms = np.sqrt(np.mean(base_audio**2, axis=0))
    overlay_rms = np.sqrt(np.mean(overlay_audio**2, axis=0))
    target_rms_overlay = base_rms / (10**(snr_db / 20))
    scaling_factor = target_rms_overlay / (overlay_rms + 1e-10)
    overlay_audio = overlay_audio * scaling_factor

    min_len = min(len(base_audio), len(overlay_audio))
    mixed_audio = base_audio[:min_len] + overlay_audio[:min_len]

    peak = np.max(np.abs(mixed_audio))
    if peak > 1.0:
        mixed_audio = mixed_audio / (peak + 1e-10)

    return mixed_audio

def load_stems(file_path):
    try:
        audio, _ = stempeg.read_stems(file_path)
        print(f"파일: {file_path}, 오디오 데이터 shape: {audio.shape}")

        vocals = audio[0]
        accompaniment = np.sum(audio[1:], axis=0)
        return vocals, accompaniment
    except Exception as e:
        print(f"Error loading stems from {file_path}: {e}")
        return None, None

def create_mixed_dataset(config_path='config.json'):
    # 기본 설정 정의
    default_config = {
        "snr_db": -5,
        "silence_duration_seconds": 3,
        "num_samples": 1,
        "sample_rate": 44100,
        "seed": 42,
        "output_dir": "/content/dataset",
        "musdb_dir": "/content/musdb18",
        "librispeech_dir": "/content/librispeech_clean/LibriSpeech"
    }

    # config.json 파일이 없으면 생성
    if not os.path.exists(config_path):
        with open(config_path, 'w') as config_file:
            json.dump(default_config, config_file, indent=4)
            print("Configuration file created successfully:", config_path)

    # config.json 파일을 로드
    with open(config_path, 'r') as config_file:
        config = json.load(config_file)
        print("Configuration loaded successfully:", config)

    # Set parameters from config
    snr_db = config['snr_db']
    num_samples = config['num_samples']
    sample_rate = config['sample_rate']
    seed = config['seed']
    output_dir = config['output_dir']
    musdb_dir = config['musdb_dir']
    librispeech_dir = config['librispeech_dir']

    if 'seed' in config:
        random.seed(seed)
        np.random.seed(seed)

    os.makedirs(output_dir, exist_ok=True)
    train_csv_path = os.path.join(output_dir, "train.csv")

    # CSV 파일 생성 및 열 제목 추가
    with open(train_csv_path, mode='w', newline='') as csv_file:
        writer = csv.writer(csv_file)
        writer.writerow([
            "mix_path", "vocals_path", "others_path", "speech_path",
            "bg_musics_path", "duration"
        ])

        musdb_tracks = [os.path.join(musdb_dir, 'train', track) for track in os.listdir(os.path.join(musdb_dir, 'train')) if track.endswith('.stem.mp4')]
        librispeech_clean_dir = os.path.join(librispeech_dir, 'train-clean-100')
        libri_tracks = [os.path.join(root, file) for root, _, files in os.walk(librispeech_clean_dir) for file in files if file.endswith('.flac')]

        for i in range(num_samples):
            song_path = random.choice(musdb_tracks)
            vocal, background = load_stems(song_path)
            if vocal is None or background is None:
                continue

            selected_speeches = []
            total_speech_length = 0

            while total_speech_length < len(background):
                speech_path = random.choice(libri_tracks)
                speech, sr_actual = librosa.load(speech_path, sr=None)

                if sr_actual != sample_rate:
                    speech = librosa.resample(speech, orig_sr=sr_actual, target_sr=sample_rate)

                random_silence_duration = random.uniform(0, config['silence_duration_seconds'])
                silence_samples = int(random_silence_duration * sample_rate)
                silence = np.zeros((silence_samples,))

                if selected_speeches:
                    selected_speeches.append(silence)
                    total_speech_length += len(silence)

                selected_speeches.append(speech)
                total_speech_length += len(speech)

                if total_speech_length >= len(background):
                    break

            combined_speech = np.concatenate(selected_speeches)
            combined_speech = combined_speech[:len(background)]

            if combined_speech.ndim == 1:
                combined_speech = np.stack((combined_speech, combined_speech), axis=-1)

            combined_speech = combined_speech[:-silence_samples] if len(combined_speech) > silence_samples else combined_speech

            # 파일 저장 경로 설정
            speech_path = os.path.join(output_dir, f"speech{i}.wav")
            bg_music_path = os.path.join(output_dir, f"bg_musics{i}.wav")
            mix_path = os.path.join(output_dir, f"mix{i}.wav")
            vocal_path = os.path.join(output_dir, f"vocals{i}.wav")
            others_path = os.path.join(output_dir, f"others{i}.wav")

            # 파일 저장
            sf.write(speech_path, combined_speech, sample_rate)
            mixed_vocal_bg = mix_audio(vocal, background, snr_db)
            final_mix = mix_audio(mixed_vocal_bg, combined_speech, snr_db)
            sf.write(bg_music_path, mixed_vocal_bg, sample_rate)
            sf.write(mix_path, final_mix, sample_rate)
            sf.write(vocal_path, vocal, sample_rate)
            sf.write(others_path, background, sample_rate)

            # CSV 파일에 경로 추가
            writer.writerow([mix_path, vocal_path, others_path, speech_path, bg_music_path, len(final_mix) / sample_rate])

# Run the function
create_mixed_dataset(config_path='config.json')